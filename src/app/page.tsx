"use client";

import { MessageBubble } from "@/components/chat/message-bubble";
import TypingIndicator from "@/components/chat/typing-indicator";
import { WaveformVisualizer } from "@/components/chat/wave-form-visualizer";
import { Button } from "@/components/ui/button";
import { Card } from "@/components/ui/card";
import { Input } from "@/components/ui/input";
import { ScrollArea } from "@/components/ui/scroll-area";
import {
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue,
} from "@/components/ui/select";
import { Separator } from "@/components/ui/separator";
import { Switch } from "@/components/ui/switch";
import type { AudioSettings, ChatPageProps, Message } from "@/utils/types/chat";
import {
  Bot,
  Mic,
  MicOff,
  Send,
  Settings,
  Volume2,
  X,
  Zap,
} from "lucide-react";
import type React from "react";
import { useCallback, useEffect, useRef, useState } from "react";

const ChatPage: React.FC<ChatPageProps> = ({
  title = "Assistant Juridique IA",
  placeholder = "Posez votre question juridique...",
  initialMessages = [],
}) => {
  const [messages, setMessages] = useState<Message[]>(initialMessages);
  const [inputValue, setInputValue] = useState("");
  const [isRecording, setIsRecording] = useState(false);
  const [isTyping, setIsTyping] = useState(false);
  const [showSettings, setShowSettings] = useState(false);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const [audioSettings, setAudioSettings] = useState<AudioSettings>({
    autoPlay: false,
    voice: "female",
    language: "fr",
    speed: 1,
  });

  // Ajouter un nouvel √©tat pour g√©rer la lecture audio
  const [playingMessageId, setPlayingMessageId] = useState<string | null>(null);
  const [shouldAutoScroll, setShouldAutoScroll] = useState(true);

  const scrollAreaRef = useRef<HTMLDivElement>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recordingStartTimeRef = useRef<number>(0);
  const recordingIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const currentPlayingAudioRef = useRef<HTMLAudioElement | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);

  const logMessage = (
    type: "USER" | "BOT" | "SYSTEM" | "AUDIO",
    content: string,
    extra?: any
  ) => {
    const timestamp = new Date().toLocaleTimeString();
    const styles = {
      USER: "color: #3b82f6; font-weight: bold;",
      BOT: "color: #10b981; font-weight: bold;",
      SYSTEM: "color: #f59e0b; font-weight: bold;",
      AUDIO: "color: #8b5cf6; font-weight: bold;",
    };
    console.log(`%c[${timestamp}] ${type}:`, styles[type], content);
    if (extra) {
      console.log("Donn√©es suppl√©mentaires:", extra);
    }
  };

  const formatDuration = (seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, "0")}`;
  };

  const scrollToBottom = useCallback(() => {
    if (scrollAreaRef.current) {
      const scrollContainer = scrollAreaRef.current.querySelector(
        "[data-radix-scroll-area-viewport]"
      );
      if (scrollContainer) {
        scrollContainer.scrollTop = scrollContainer.scrollHeight;
      }
    }
  }, []);

  useEffect(() => {
    // Ne scroll que si on doit auto-scroll (nouveaux messages, typing, etc.)
    if (shouldAutoScroll) {
      scrollToBottom();
    }
  }, [messages.length, isTyping, scrollToBottom, shouldAutoScroll]); // Utiliser messages.length au lieu de messages

  useEffect(() => {
    const savedMessages = localStorage.getItem("chat-messages");
    if (savedMessages) {
      try {
        const parsed = JSON.parse(savedMessages).map(
          (msg: { timestamp: string | number | Date }) => ({
            ...msg,
            timestamp: new Date(msg.timestamp),
            // Ne pas recr√©er les URLs audio car les blobs ne sont pas persistants
            audioUrl: undefined,
          })
        );
        setMessages(parsed);
        logMessage(
          "SYSTEM",
          `${parsed.length} messages charg√©s depuis le localStorage`
        );
      } catch (error) {
        console.error("Error loading saved messages:", error);
        logMessage(
          "SYSTEM",
          "Erreur lors du chargement des messages sauvegard√©s",
          error
        );
      }
    }
  }, []);

  useEffect(() => {
    if (messages.length > 0) {
      // Sauvegarder sans les URLs et blobs audio (non persistants)
      const messagesToSave = messages.map((msg) => ({
        ...msg,
        audioUrl: undefined,
        audioBlob: undefined,
      }));
      localStorage.setItem("chat-messages", JSON.stringify(messagesToSave));
      logMessage(
        "SYSTEM",
        `${messages.length} messages sauvegard√©s dans le localStorage`
      );
    }
  }, [messages]);

  const cleanupRecording = () => {
    // Nettoyer les chunks audio
    audioChunksRef.current = [];

    // Arr√™ter et nettoyer le timer
    if (recordingIntervalRef.current) {
      clearInterval(recordingIntervalRef.current);
      recordingIntervalRef.current = null;
    }

    // Fermer tous les tracks audio
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((track) => {
        track.stop();
        logMessage("AUDIO", "üîá Track audio ferm√© lors du nettoyage");
      });
      mediaStreamRef.current = null;
    }

    // R√©initialiser les √©tats
    setIsRecording(false);
    setRecordingDuration(0);

    // Nettoyer la r√©f√©rence du MediaRecorder
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current = null;
    }

    setShouldAutoScroll(true); // R√©activer le scroll automatique apr√®s nettoyage

    logMessage("AUDIO", "üßπ Nettoyage complet de l'enregistrement effectu√©");
  };

  const startRecording = async () => {
    try {
      setShouldAutoScroll(false); // D√©sactiver le scroll pendant l'enregistrement
      logMessage("AUDIO", "D√©marrage de l'enregistrement vocal...");
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100,
        },
      });

      // Stocker la r√©f√©rence du stream pour le nettoyage
      mediaStreamRef.current = stream;

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: "audio/webm;codecs=opus",
      });

      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];
      recordingStartTimeRef.current = Date.now();
      setRecordingDuration(0);

      // D√©marrer le compteur de dur√©e
      recordingIntervalRef.current = setInterval(() => {
        const elapsed = (Date.now() - recordingStartTimeRef.current) / 1000;
        setRecordingDuration(elapsed);
      }, 100);

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          logMessage("AUDIO", `Chunk audio re√ßu: ${event.data.size} bytes`);
        }
      };

      mediaRecorder.onstop = async () => {
        const duration = (Date.now() - recordingStartTimeRef.current) / 1000;

        if (audioChunksRef.current.length === 0) {
          logMessage("AUDIO", "‚ùå Aucun chunk audio re√ßu");
          cleanupRecording();
          return;
        }

        const audioBlob = new Blob(audioChunksRef.current, {
          type: "audio/webm;codecs=opus",
        });

        logMessage("AUDIO", "‚úÖ Enregistrement termin√© avec succ√®s", {
          size: `${(audioBlob.size / 1024).toFixed(1)} KB`,
          type: audioBlob.type,
          duration: `${duration.toFixed(1)}s`,
          chunks: audioChunksRef.current.length,
        });

        // Cr√©er l'URL pour la lecture imm√©diate
        const audioUrl = URL.createObjectURL(audioBlob);

        // Tester que l'URL fonctionne
        const testAudio = new Audio(audioUrl);
        testAudio.oncanplay = () => {
          logMessage("AUDIO", "‚úÖ URL audio cr√©√©e et test√©e avec succ√®s");
        };
        testAudio.onerror = () => {
          logMessage("AUDIO", "‚ùå Erreur lors du test de l'URL audio");
        };

        // Cr√©er le message audio directement (sans transcription)
        const audioMessage: Message = {
          id: Date.now().toString(),
          sender: "user",
          timestamp: new Date(),
          type: "audio",
          audioBlob,
          audioUrl,
          duration,
        };

        // Ajouter le message √† la conversation
        setMessages((prev) => [...prev, audioMessage]);
        logMessage("USER", `üé§ Message vocal envoy√© directement`, {
          messageId: audioMessage.id,
          duration: `${duration.toFixed(1)}s`,
          size: `${(audioBlob.size / 1024).toFixed(1)} KB`,
          url: audioUrl.substring(0, 50) + "...",
        });

        // D√©clencher la r√©ponse de l'IA
        handleAIResponse(audioMessage);

        // Nettoyer apr√®s traitement r√©ussi
        cleanupRecording();
      };

      mediaRecorder.start(100); // Collecter des chunks toutes les 100ms
      setIsRecording(true);
      logMessage("AUDIO", "Enregistrement d√©marr√© avec succ√®s");
    } catch (error) {
      console.error("Error starting recording:", error);
      logMessage(
        "AUDIO",
        "Erreur lors du d√©marrage de l'enregistrement",
        error
      );
      setShouldAutoScroll(true); // R√©activer en cas d'erreur
      cleanupRecording();
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      logMessage("AUDIO", "Arr√™t de l'enregistrement demand√©");
    }
  };

  const cancelRecording = () => {
    logMessage("AUDIO", "üö´ Annulation de l'enregistrement demand√©e");

    // Arr√™ter l'enregistrement si en cours
    if (mediaRecorderRef.current && isRecording) {
      // Supprimer les event listeners pour √©viter le traitement
      mediaRecorderRef.current.ondataavailable = null;
      mediaRecorderRef.current.onstop = null;

      // Arr√™ter l'enregistrement
      try {
        mediaRecorderRef.current.stop();
      } catch (error) {
        logMessage("AUDIO", "Erreur lors de l'arr√™t du MediaRecorder", error);
      }
    }

    // Nettoyer compl√®tement
    cleanupRecording();

    logMessage("AUDIO", "‚úÖ Enregistrement annul√© avec succ√®s");
  };

  const sendMessage = async () => {
    if (!inputValue.trim()) {
      logMessage("SYSTEM", "Tentative d'envoi d'un message vide - ignor√©");
      return;
    }

    const userMessage: Message = {
      id: Date.now().toString(),
      content: inputValue,
      sender: "user",
      timestamp: new Date(),
      type: "text",
    };

    // Log du message utilisateur
    logMessage("USER", inputValue, {
      messageId: userMessage.id,
      timestamp: userMessage.timestamp,
      length: inputValue.length,
    });

    setMessages((prev) => [...prev, userMessage]);
    setInputValue("");

    // D√©clencher la r√©ponse de l'IA
    handleAIResponse(userMessage);
  };

  const handleAIResponse = (userMessage: Message) => {
    setIsTyping(true);
    setShouldAutoScroll(true); // S'assurer que le scroll est activ√© pour les nouvelles r√©ponses
    logMessage("SYSTEM", "IA en train de taper...");

    // Simulate AI response
    setTimeout(() => {
      let botResponse: string;
      if (userMessage.type === "audio") {
        botResponse =
          "J'ai bien re√ßu votre message vocal. En tant qu'assistant juridique IA, je peux vous aider avec vos questions juridiques. Pouvez-vous me donner plus de d√©tails sur votre situation ?";
      } else {
        botResponse = `En tant qu'assistant juridique IA, je peux vous aider avec votre question : "${userMessage.content}". Voici une r√©ponse d√©taill√©e bas√©e sur le droit fran√ßais applicable...`;
      }

      const botMessage: Message = {
        id: (Date.now() + 1).toString(),
        content: botResponse,
        sender: "bot",
        timestamp: new Date(),
        type: "text",
      };

      // Log de la r√©ponse de l'IA
      logMessage("BOT", botResponse, {
        messageId: botMessage.id,
        timestamp: botMessage.timestamp,
        responseTime: "2000ms",
        length: botResponse.length,
      });

      setMessages((prev) => [...prev, botMessage]);
      setIsTyping(false);

      if (audioSettings.autoPlay) {
        logMessage(
          "AUDIO",
          "Lecture automatique activ√©e - d√©marrage de la synth√®se vocale"
        );
        playMessageAudio(botMessage.id, botMessage.content!);
      }
    }, 2000);
  };

  const playMessageAudio = (messageId: string, text: string) => {
    if ("speechSynthesis" in window) {
      logMessage("AUDIO", "D√©marrage de la synth√®se vocale", {
        messageId,
        textLength: text.length,
        language: audioSettings.language,
        voice: audioSettings.voice,
        speed: audioSettings.speed,
      });

      // Arr√™ter toute lecture en cours
      speechSynthesis.cancel();
      setPlayingMessageId(null);

      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = audioSettings.language === "fr" ? "fr-FR" : "en-US";
      utterance.rate = audioSettings.speed;

      const voices = speechSynthesis.getVoices();
      const selectedVoice = voices.find(
        (voice) =>
          voice.lang.startsWith(audioSettings.language) &&
          (audioSettings.voice === "female"
            ? voice.name.includes("Female") || voice.name.includes("femme")
            : voice.name.includes("Male") || voice.name.includes("homme"))
      );

      if (selectedVoice) {
        utterance.voice = selectedVoice;
        logMessage("AUDIO", `Voix s√©lectionn√©e: ${selectedVoice.name}`);
      } else {
        logMessage(
          "AUDIO",
          "Aucune voix sp√©cifique trouv√©e - utilisation de la voix par d√©faut"
        );
      }

      utterance.onstart = () => {
        logMessage(
          "AUDIO",
          `Lecture audio d√©marr√©e pour le message ${messageId}`
        );
        setPlayingMessageId(messageId);
        setShouldAutoScroll(false); // D√©sactiver le scroll automatique pendant la lecture
      };

      utterance.onend = () => {
        logMessage(
          "AUDIO",
          `Lecture audio termin√©e pour le message ${messageId}`
        );
        setPlayingMessageId(null);
        setShouldAutoScroll(true); // R√©activer le scroll automatique
      };

      utterance.onerror = (event) => {
        logMessage("AUDIO", "Erreur lors de la synth√®se vocale", event);
        setPlayingMessageId(null);
        setShouldAutoScroll(true);
      };

      speechSynthesis.speak(utterance);
    } else {
      logMessage("AUDIO", "Synth√®se vocale non support√©e par ce navigateur");
    }
  };

  const playRecordedAudio = (messageId: string, audioUrl: string) => {
    logMessage("AUDIO", `üéµ Lecture de votre message vocal (ID: ${messageId})`);

    // Arr√™ter l'audio en cours s'il y en a un
    if (currentPlayingAudioRef.current) {
      currentPlayingAudioRef.current.pause();
      currentPlayingAudioRef.current = null;
    }

    // Arr√™ter la synth√®se vocale si active
    speechSynthesis.cancel();
    setPlayingMessageId(null);

    const audio = new Audio(audioUrl);
    currentPlayingAudioRef.current = audio;

    // Am√©liorer la qualit√© audio
    audio.preload = "auto";
    audio.volume = 1.0;

    audio.onloadstart = () => {
      logMessage("AUDIO", "üîÑ Chargement de l'audio...");
    };

    audio.oncanplay = () => {
      logMessage("AUDIO", "‚úÖ Audio pr√™t √† √™tre lu");
    };

    audio.onplay = () => {
      setPlayingMessageId(messageId);
      setShouldAutoScroll(false); // D√©sactiver le scroll automatique pendant la lecture
      logMessage("AUDIO", `‚ñ∂Ô∏è Lecture d√©marr√©e pour votre message vocal`);
    };

    audio.onended = () => {
      setPlayingMessageId(null);
      setShouldAutoScroll(true); // R√©activer le scroll automatique
      currentPlayingAudioRef.current = null;
      logMessage("AUDIO", `‚èπÔ∏è Lecture termin√©e pour votre message vocal`);
    };

    audio.onerror = (error) => {
      logMessage(
        "AUDIO",
        "‚ùå Erreur lors de la lecture de votre message vocal",
        error
      );
      setPlayingMessageId(null);
      setShouldAutoScroll(true);
      currentPlayingAudioRef.current = null;
    };

    audio.onpause = () => {
      logMessage("AUDIO", "‚è∏Ô∏è Lecture mise en pause");
      setPlayingMessageId(null);
      setShouldAutoScroll(true);
    };

    // D√©marrer la lecture
    audio.play().catch((error) => {
      logMessage("AUDIO", "‚ùå Erreur lors du d√©marrage de la lecture", error);
      setPlayingMessageId(null);
      setShouldAutoScroll(true);
      console.warn(
        "La lecture automatique peut √™tre bloqu√©e. Cliquez pour √©couter."
      );
    });
  };

  const pauseAudio = (messageId: string) => {
    // Arr√™ter la synth√®se vocale
    speechSynthesis.cancel();

    // Arr√™ter l'audio en cours
    if (currentPlayingAudioRef.current) {
      currentPlayingAudioRef.current.pause();
      currentPlayingAudioRef.current.currentTime = 0;
      currentPlayingAudioRef.current = null;
    }

    logMessage(
      "AUDIO",
      `Audio mis en pause/arr√™t√© pour le message ${messageId}`
    );
    setPlayingMessageId(null);
    setShouldAutoScroll(true); // R√©activer le scroll automatique
  };

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      logMessage("SYSTEM", "Envoi du message via la touche Entr√©e");
      sendMessage();
    }
  };

  const handleAudioSettingsChange = (
    setting: keyof AudioSettings,
    value: any
  ) => {
    setAudioSettings((prev) => ({ ...prev, [setting]: value }));
    logMessage("SYSTEM", `Param√®tre audio modifi√©: ${setting} = ${value}`);
  };

  return (
    <div className="flex flex-col h-screen bg-background mwx">
      <header className="sticky top-0 w-full rounded-xl mt-3 border bg-card p-4 ">
        <div className="bg-background/5 backdrop-blur-md transition-colors duration-300">
          <div className="flex items-center justify-between w-full">
            <div className="flex items-center space-x-3">
              <div className="w-10 h-10 bg-primary/10 rounded-lg flex items-center justify-center">
                <Zap className="w-5 h-5 text-primary" />
              </div>
              <div>
                <h1 className="text-lg font-semibold text-foreground">
                  Irokolaw
                </h1>
                <p className="text-sm text-muted-foreground">
                  Assistant IA sp√©cialis√© en droit
                </p>
              </div>
            </div>
            <Button
              variant="ghost"
              size="sm"
              onClick={() => {
                setShowSettings(!showSettings);
                logMessage(
                  "SYSTEM",
                  `Param√®tres ${!showSettings ? "ouverts" : "ferm√©s"}`
                );
              }}
              className="flex-shrink-0"
            >
              <Settings className="w-4 h-4" />
            </Button>
          </div>
          {/* Panel des param√®tres */}
          {showSettings && (
            <>
              <Separator className="my-4" />
              <div className="p-4 bg-muted/30 rounded-lg">
                <div className="grid grid-cols-1 md:grid-cols-4 gap-4">
                  <div className="flex items-center space-x-2">
                    <Switch
                      checked={audioSettings.autoPlay}
                      onCheckedChange={(checked) =>
                        handleAudioSettingsChange("autoPlay", checked)
                      }
                    />
                    <span className="text-sm">Lecture auto</span>
                  </div>
                  <Select
                    value={audioSettings.voice}
                    onValueChange={(value: "male" | "female") =>
                      handleAudioSettingsChange("voice", value)
                    }
                  >
                    <SelectTrigger className="h-8">
                      <SelectValue />
                    </SelectTrigger>
                    <SelectContent>
                      <SelectItem value="female">Voix f√©minine</SelectItem>
                      <SelectItem value="male">Voix masculine</SelectItem>
                    </SelectContent>
                  </Select>
                  <Select
                    value={audioSettings.language}
                    onValueChange={(value: "fr" | "en") =>
                      handleAudioSettingsChange("language", value)
                    }
                  >
                    <SelectTrigger className="h-8">
                      <SelectValue />
                    </SelectTrigger>
                    <SelectContent>
                      <SelectItem value="fr">Fran√ßais</SelectItem>
                      <SelectItem value="en">English</SelectItem>
                    </SelectContent>
                  </Select>
                  <Select
                    value={audioSettings.speed.toString()}
                    onValueChange={(value) =>
                      handleAudioSettingsChange(
                        "speed",
                        Number.parseFloat(value)
                      )
                    }
                  >
                    <SelectTrigger className="h-8">
                      <SelectValue />
                    </SelectTrigger>
                    <SelectContent>
                      <SelectItem value="0.5">0.5x</SelectItem>
                      <SelectItem value="1">1x</SelectItem>
                      <SelectItem value="1.5">1.5x</SelectItem>
                      <SelectItem value="2">2x</SelectItem>
                    </SelectContent>
                  </Select>
                </div>
              </div>
            </>
          )}
        </div>
      </header>

      <ScrollArea ref={scrollAreaRef} className="flex-1 p-4 mt-32">
        <div>
          {messages.length === 0 && (
            <div className="text-center py-12">
              <div className="w-16 h-16 bg-primary/10 rounded-full flex items-center justify-center mx-auto mb-4">
                <Bot className="w-8 h-8 text-primary" />
              </div>
              <h3 className="text-lg font-medium text-foreground mb-2">
                Bonjour ! Comment puis-je vous aider ?
              </h3>
              <p className="text-muted-foreground">
                Posez votre question juridique par √©crit ou envoyez un message
                vocal
              </p>
            </div>
          )}
          {messages.map((message) => (
            <MessageBubble
              key={message.id}
              message={{
                ...message,
                isPlaying: playingMessageId === message.id,
              }}
              onPlayAudio={playMessageAudio}
              onPauseAudio={pauseAudio}
              onPlayRecordedAudio={playRecordedAudio}
              formatDuration={formatDuration}
            />
          ))}
          {isTyping && <TypingIndicator />}
        </div>
      </ScrollArea>

      <footer className="sticky bottom-0 w-full bg-card p-4 z-50">
        <div>
          {isRecording && (
            <Card className="p-4 mb-4 bg-primary/5 border-primary/20">
              <div className="flex items-center justify-between">
                <div className="flex items-center space-x-3">
                  <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse" />
                  <span className="text-sm font-medium">
                    üé§ Enregistrement... {formatDuration(recordingDuration)}
                  </span>
                </div>
                <WaveformVisualizer isRecording={isRecording} />
              </div>
              <div className="mt-3 flex items-center justify-between">
                <p className="text-xs text-muted-foreground">
                  Cliquez sur "Arr√™ter" pour envoyer ou "Annuler" pour
                  abandonner
                </p>
                <div className="flex items-center space-x-2">
                  <Button
                    variant="outline"
                    size="sm"
                    onClick={cancelRecording}
                    className="h-8 px-3 text-xs border-destructive/20 text-destructive hover:bg-destructive/10 hover:text-destructive bg-transparent"
                  >
                    <X className="w-3 h-3 mr-1" />
                    Annuler
                  </Button>
                  <Button
                    variant="default"
                    size="sm"
                    onClick={stopRecording}
                    className="h-8 px-3 text-xs bg-primary hover:bg-primary/90"
                  >
                    <Send className="w-3 h-3 mr-1" />
                    Envoyer
                  </Button>
                </div>
              </div>
            </Card>
          )}
          <div className="flex items-end space-x-2">
            <div className="flex-1 relative">
              <Input
                value={inputValue}
                onChange={(e) => setInputValue(e.target.value)}
                onKeyDown={handleKeyPress}
                placeholder={placeholder}
                className="pr-12 min-h-[44px] resize-none"
                disabled={isRecording}
              />
            </div>
            <Button
              variant={isRecording ? "destructive" : "outline"}
              size="sm"
              className="h-[44px] w-[44px] p-0"
              onClick={
                inputValue.trim() && !isRecording
                  ? sendMessage
                  : isRecording
                  ? stopRecording
                  : startRecording
              }
            >
              {isRecording ? (
                <MicOff className="w-4 h-4" />
              ) : !inputValue.trim() ? (
                <Mic className="w-4 h-4" />
              ) : (
                <Send className="w-4 h-4" />
              )}
            </Button>
          </div>
          <div className="flex items-center justify-between mt-2 text-xs text-muted-foreground">
            <span>
              Appuyez sur Entr√©e pour envoyer ‚Ä¢ Cliquez sur üé§ pour un message
              vocal
            </span>
            <div className="flex items-center space-x-2">
              <Volume2 className="w-3 h-3" />
              <span>
                Audio {audioSettings.autoPlay ? "activ√©" : "d√©sactiv√©"}
              </span>
            </div>
          </div>
        </div>
      </footer>
    </div>
  );
};

export default ChatPage;
